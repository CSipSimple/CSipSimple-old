Index: webrtc/sources/modules/video_capture/main/source/video_capture_impl.cc
===================================================================
--- webrtc.orig/sources/modules/video_capture/main/source/video_capture_impl.cc	2012-09-28 20:46:34.155880836 +0200
+++ webrtc/sources/modules/video_capture/main/source/video_capture_impl.cc	2012-09-30 00:16:59.712266528 +0200
@@ -11,6 +11,7 @@
 #include "video_capture_impl.h"
 
 #include "common_video/libyuv/include/webrtc_libyuv.h"
+#include "common_video/libyuv/include/scaler.h"
 #include "critical_section_wrapper.h"
 #include "module_common_types.h"
 #include "ref_count.h"
@@ -290,6 +291,29 @@
         // In Windows, the image starts bottom left, instead of top left.
         // Setting a negative source height, inverts the image (within LibYuv).
         _captureFrame.SetHeight(abs(height));
+
+
+        // Libyuv doesn't crop or scale in convert method
+        // So width/height of target frame has to be correct regarding expected rotation mode
+        // see discution here http://code.google.com/p/libyuv/issues/detail?id=18
+        VideoFrame* targetFramePt =  &_captureFrame;
+        // TODO - tmp frame recreation should be avoided at each loop
+        // But I want minimum impact of webrtc code for now --
+        // to be reviewed when integrated to webrtc code if accepted
+        VideoFrame tmpFrame;
+        if(_rotateFrame == kRotate90 || _rotateFrame == kRotate270){
+		int tmpRequiredLength = CalcBufferSize(kI420, height, width);
+		tmpFrame.VerifyAndAllocate(tmpRequiredLength);
+		if (!tmpFrame.Buffer()) {
+			WEBRTC_TRACE(webrtc::kTraceError, webrtc::kTraceVideoCapture, _id,
+				"Failed to allocate frame buffer.");
+			return -1;
+		}
+		tmpFrame.SetWidth(height);
+		tmpFrame.SetHeight(width);
+		targetFramePt = &tmpFrame;
+        }
+
         // TODO(mikhal) : Set stride when available.
         const int conversionResult = ConvertToI420(commonVideoType,
                                                    videoFrame,
@@ -297,7 +321,7 @@
                                                    width, height,
                                                    videoFrameLength,
                                                    _rotateFrame,
-                                                   &_captureFrame);
+                                                   targetFramePt);
         if (conversionResult < 0)
         {
             WEBRTC_TRACE(webrtc::kTraceError, webrtc::kTraceVideoCapture, _id,
@@ -305,6 +329,30 @@
                        frameInfo.rawType);
             return -1;
         }
+
+        // Finalize rotation with a scale to display proper image
+        if(_rotateFrame == kRotate90 || _rotateFrame == kRotate270){
+        	// TODO : this should maybe instanciated only once too
+        	Scaler scaler;
+        	int retVal = 0;
+        	retVal = scaler.Set(height, width,
+        	                       width, height, kI420, kI420, kScaleBox);
+        	if (retVal < 0)
+			{
+				WEBRTC_TRACE(webrtc::kTraceError, webrtc::kTraceVideoCapture, _id,
+						   "Failed to init scaler of I420 frame for rotation constraint");
+				return -1;
+			}
+        	retVal = scaler.Scale(tmpFrame.Buffer(), _captureFrame.Buffer(), requiredLength);
+        	if (retVal < 0)
+			{
+				WEBRTC_TRACE(webrtc::kTraceError, webrtc::kTraceVideoCapture, _id,
+						   "Failed to scale I420 frame due to rotation constraint");
+				return -1;
+			}
+        }
+
+
         _captureFrame.SetLength(requiredLength);
     }
     else // Encoded format
